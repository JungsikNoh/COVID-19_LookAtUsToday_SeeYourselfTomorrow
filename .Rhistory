# an example of t-test
tumorSizeWT <- rnorm(n=30, mean=7, sd=1)
tumorSizeMT <- rnorm(n=40, mean=6, sd=1)
tumorSizeWT
tumorSizeMT
summary(tumorSizeMT)
summary(tumorSizeWT)
# data visualization using density()
plot(density(tumorSizeWT), xlim=c(2, 11), ylim=c(0, 0.6))
# data visualization using density()
# data visualization using density()
plot(density(tumorSizeWT), xlim=c(2, 11), ylim=c(0, 0.6))
# data visualization using density()
plot(density(tumorSizeWT), xlim=c(2, 11), ylim=c(0, 0.6))
plot(density(tumorSizeMT), col='red', xlim=c(2,11), ylim=c(0, 0.6))
# data visualization using density()
plot(density(tumorSizeWT), xlim=c(2, 11), ylim=c(0, 0.6))
lines(density(tumorSizeMT), col='red', xlim=c(2,11), ylim=c(0, 0.6))
# data visualization using boxplot
tumorSize <- c(tumorSizeWT, tumorSizeMT)
c(rep("WT", 30), rep("MT", 40))
tumorSize
cond
# data visualization using boxplot
tumorSize <- c(tumorSizeWT, tumorSizeMT)
cond <- c(rep("WT", 30), rep("MT", 40))
boxplot(tumorSize ~ cond)
# Student's t-test
t.test(x=tumorSizeWT, y=tumorSizeMT)
# Student's t-test
t.test(x=tumorSizeWT, y=tumorSizeMT)
# an example of t-test
tumorSizeWT <- rnorm(n=30, mean=7, sd=1)
tumorSizeMT <- rnorm(n=40, mean=6, sd=1)
# data visualization using density()
plot(density(tumorSizeWT), xlim=c(2, 11), ylim=c(0, 0.6))
lines(density(tumorSizeMT), col='red', xlim=c(2,11), ylim=c(0, 0.6))
# data visualization using boxplot
tumorSize <- c(tumorSizeWT, tumorSizeMT)
cond <- c(rep("WT", 30), rep("MT", 40))
boxplot(tumorSize ~ cond)
# Student's t-test
t.test(x=tumorSizeWT, y=tumorSizeMT)
#setwd('C:/forgithub/COVID19_LookAtUsTodaySeeYourselfTomorrow')
print(getwd())
library(ggplot2)
library(data.table)
library(formattable)
library(ggpubr)
setwd('C:/githubClone/COVID-19_LookAtUsToday_SeeYourselfTomorrow')
print(getwd())
urlJhu = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'
jhudat = read.csv(urlJhu, head=T)
# china curation
idPrv = which(jhudat$Country.Region=='China')
chinaPrv = jhudat[idPrv, ]
chinaPrvTS = chinaPrv[, 5:ncol(jhudat)]
chinaTS = colSums(chinaPrvTS)
chinaHead = data.frame(Province.State='', 'Country.Region'='China', Lat=NA, Long=NA)
chinaDP = cbind(chinaHead, rbind(chinaTS))
jhudat = rbind(chinaDP, jhudat[-idPrv, ])
head(jhudat)
# canada curation
idPrv = which(jhudat$Country.Region=='Canada')
chinaPrv = jhudat[idPrv, ]
chinaPrvTS = chinaPrv[, 5:ncol(jhudat)]
chinaTS = colSums(chinaPrvTS)
chinaHead = data.frame(Province.State='', 'Country.Region'='Canada', Lat=NA, Long=NA)
chinaDP = cbind(chinaHead, rbind(chinaTS))
jhudat = rbind(chinaDP, jhudat[-idPrv, ])
head(jhudat)
setwd('C:/forgithub/COVID19_LookAtUsTodaySeeYourselfTomorrow')
print(getwd())
add.col<-function(df, new.col) {
df = cbind(df)
n.row<-dim(df)[1]
length(new.col)<-n.row
#tmp <- cbind(rep(NA, n.row))
#tmp[(n.row - length(new.col) + 1):n.row] <- new.col
cbind(df, new.col)
}
setwd('C:/forgithub/COVID19_LookAtUsTodaySeeYourselfTomorrow')
print(getwd())
outPathGIF = file.path(getwd(), 'gif_log_0419')
if (!dir.exists(outPathGIF)) dir.create(outPathGIF, recursive = T)
#
head(jhudat)
class(jhudat)
names(jhudat)
head(jhudat)
class(jhudat)
names(jhudat)
countryName = jhudat$Country.Region
head(countryName)
ind = which(countryName == 'Korea, South')
tmp = jhudat[ind,]
head(t(tmp))
tmp2 = t(tmp[5:length(tmp)])
#plot(tmp2)
#describe(jhudat)
KOts0 = tmp2
tmp = jhudat[which(countryName == 'Italy'),]
head(t(tmp))
tmp2 = t(tmp[5:length(tmp)])
#plot(tmp2)
ITts0 = tmp2
# stname =  country name
tmp = jhudat[which((countryName == 'US') & (jhudat$Province.State == '')), ]
head(t(tmp))
tmp2 = t(tmp[5:length(tmp)])
plot(tmp2)
Xts0 = tmp2
# start with 'datf'
datf = data.frame(Korea=KOts0, Italy=ITts0, US=Xts0)
colnames(datf) = c('Korea', 'Italy', 'US')
## manual curation, two zeros in Italy and Korea from Wikipedia
datfrow = rownames(datf)
id = which(datfrow == 'X3.12.20')     # Italy
datf[id, 2] = 15113
id = which(datfrow == 'X3.22.20')     # Korea
datf[id, 1] = 8897
####################################################
##
tmp = jhudat[which((countryName == 'Spain') & (jhudat$Province.State == '')), ]
head(t(tmp))
tmp2 = t(tmp[5:length(tmp)])
colnames(tmp2) = 'Spain'
datf = add.col(datf, tmp2)
##
tmp = jhudat[which((countryName == 'France') & (jhudat$Province.State == '')), ]
head(t(tmp))
tmp2 = t(tmp[5:length(tmp)])
colnames(tmp2) = 'France'
datf = add.col(datf, tmp2)
##
tmp = jhudat[which((countryName == 'Germany') & (jhudat$Province.State == '')), ]
head(t(tmp))
tmp2 = t(tmp[5:length(tmp)])
colnames(tmp2) = 'Germany'
datf = add.col(datf, tmp2)
##
tmp = jhudat[which((countryName == 'United Kingdom') & (jhudat$Province.State == '')), ]
head(t(tmp))
tmp2 = t(tmp[5:length(tmp)])
colnames(tmp2) = 'UK'
datf = add.col(datf, tmp2)
#######
## manual curation, two zeros in Italy and Korea from Wikipedia
datfrow = rownames(datf)
id = which(datfrow == 'X3.12.20')     #
datf$Spain[id] = 3146
id = which(datfrow == 'X3.12.20')     #
datf$France[id] = 2876
id = which(datfrow == 'X4.18.20')     #
datf$France[id] = 152978              # JHU 19 morning update dashboard
id = which(datfrow == 'X3.12.20')     #
datf$UK[id] = 590
id = which(datfrow == 'X3.15.20')     #
datf$UK[id] = 1391
########
datf1 = data.matrix(datf)
datf1[which(datf1 <= 100)] = NA
datf1tm1 = datf1
datf1tm1[2:nrow(datf1), ] = datf1[1:(nrow(datf1)-1), ]
grmat0 = (datf1 - datf1tm1) / datf1tm1 * 100
grmat1 = grmat0[, 2:7]
########
#id0 = rowSums(!is.na(grmat1))
#grmat2 = grmat1[(id0 != 0), ]
numDays = nrow(grmat1)
dvec = -(numDays-1):0
daymat = matrix(cbind(dvec), nrow(grmat1), 6)
daymat1 = daymat
daymat1[, 2] = dvec - 15
daymat1[, 3] = dvec - 7
daymat1[, 4] = dvec - 15
daymat1[, 5] = dvec - 1
daymat1[, 6] = dvec - 16
colnames(daymat1) = paste0(colnames(grmat1), '_day')
stDate = 'X2.24.20'     # Italy start
#endDate = 'X3.24.20'
curDate = 'X4.19.20'
idst = which(rownames(grmat1) == stDate)
idend = which(rownames(grmat1) == curDate)
grdaymat = cbind(grmat1, daymat1)
grdaymat1 =  grdaymat[idst:idend, ]
daystart = min(grdaymat1[1, 7:12])
##  date
rowdates = rownames(grdaymat1)
tmp = strsplit(rowdates, ".", fixed=T)
mmm = lapply(tmp, function(x) substr(x[1], 2, 2))
ddd = lapply(tmp, function(x) x[2])
mydates = rowdates
for (i in 1:length(mmm)){
mydates[i] = as.character(as.Date(paste0("2020-", mmm[[i]], "-", ddd[[i]])))
}
rownames(grdaymat1) = mydates
grdaymat1[, 1:6] = log10(grdaymat1[, 1:6])
j
#
head(jhudat)
class(jhudat)
names(jhudat)
countryName = jhudat$Country.Region
head(countryName)
ind = which(countryName == 'Korea, South')
tmp = jhudat[ind,]
head(t(tmp))
tmp2 = t(tmp[5:length(tmp)])
#plot(tmp2)
#describe(jhudat)
KOts0 = tmp2
tmp = jhudat[which(countryName == 'Italy'),]
head(t(tmp))
tmp2 = t(tmp[5:length(tmp)])
#plot(tmp2)
ITts0 = tmp2
# stname =  country name
tmp = jhudat[which((countryName == 'US') & (jhudat$Province.State == '')), ]
head(t(tmp))
tmp2 = t(tmp[5:length(tmp)])
plot(tmp2)
Xts0 = tmp2
# start with 'datf'
datf = data.frame(Korea=KOts0, Italy=ITts0, US=Xts0)
colnames(datf) = c('Korea', 'Italy', 'US')
## manual curation, two zeros in Italy and Korea from Wikipedia
datfrow = rownames(datf)
id = which(datfrow == 'X3.12.20')     # Italy
datf[id, 2] = 15113
id = which(datfrow == 'X3.22.20')     # Korea
datf[id, 1] = 8897
##
tmp = jhudat[which((countryName == 'Spain') & (jhudat$Province.State == '')), ]
head(t(tmp))
tmp2 = t(tmp[5:length(tmp)])
colnames(tmp2) = 'Spain'
datf = add.col(datf, tmp2)
##
tmp = jhudat[which((countryName == 'France') & (jhudat$Province.State == '')), ]
head(t(tmp))
tmp2 = t(tmp[5:length(tmp)])
colnames(tmp2) = 'France'
datf = add.col(datf, tmp2)
##
tmp = jhudat[which((countryName == 'Germany') & (jhudat$Province.State == '')), ]
head(t(tmp))
tmp2 = t(tmp[5:length(tmp)])
colnames(tmp2) = 'Germany'
datf = add.col(datf, tmp2)
##
tmp = jhudat[which((countryName == 'United Kingdom') & (jhudat$Province.State == '')), ]
head(t(tmp))
tmp2 = t(tmp[5:length(tmp)])
colnames(tmp2) = 'UK'
datf = add.col(datf, tmp2)
#######
## manual curation, two zeros in Italy and Korea from Wikipedia
datfrow = rownames(datf)
id = which(datfrow == 'X3.12.20')     #
datf$Spain[id] = 3146
id = which(datfrow == 'X3.12.20')     #
datf$France[id] = 2876
id = which(datfrow == 'X4.18.20')     #
datf$France[id] = 152978              # JHU 19 morning update dashboard
id = which(datfrow == 'X3.12.20')     #
datf$UK[id] = 590
id = which(datfrow == 'X3.15.20')     #
datf$UK[id] = 1391
########
datf1 = data.matrix(datf)
datf1[which(datf1 <= 100)] = NA
datf1tm1 = datf1
datf1tm1[2:nrow(datf1), ] = datf1[1:(nrow(datf1)-1), ]
grmat0 = (datf1 - datf1tm1) / datf1tm1 * 100
grmat1 = grmat0[, 2:7]
numDays = nrow(grmat1)
dvec = -(numDays-1):0
daymat = matrix(cbind(dvec), nrow(grmat1), 6)
daymat1 = daymat
daymat1[, 2] = dvec - 15
daymat1[, 3] = dvec - 7
daymat1[, 4] = dvec - 15
daymat1[, 5] = dvec - 1
daymat1[, 6] = dvec - 16
colnames(daymat1) = paste0(colnames(grmat1), '_day')
stDate = 'X2.24.20'     # Italy start
#endDate = 'X3.24.20'
curDate = 'X4.19.20'
idst = which(rownames(grmat1) == stDate)
idend = which(rownames(grmat1) == curDate)
grdaymat = cbind(grmat1, daymat1)
grdaymat1 =  grdaymat[idst:idend, ]
daystart = min(grdaymat1[1, 7:12])
rowdates = rownames(grdaymat1)
View(daymat1)
tmp = strsplit(rowdates, ".", fixed=T)
mmm = lapply(tmp, function(x) substr(x[1], 2, 2))
ddd = lapply(tmp, function(x) x[2])
mydates = rowdates
for (i in 1:length(mmm)){
mydates[i] = as.character(as.Date(paste0("2020-", mmm[[i]], "-", ddd[[i]])))
}
rownames(grdaymat1) = mydates
grdaymat1[, 1:6] = log10(grdaymat1[, 1:6])
View(grdaymat1)
t1 = Sys.time()
for (K in 7:nrow(grdaymat1)){
#K = 10, nrow(grdaymat1)
idVec = 1:K
tmp = grdaymat1[idVec, ]
#tmp2 = tmp[, 1:6]
#tmp2[1:29, ] = NA
#colnames(tmp2) = paste0(colnames(tmp[, 1:6]), 'Last')
#tmp3 = cbind(tmp, tmp2)
## Daily Growth Rate Time Series
cname = as.factor(paste0(colnames(tmp[, 1:6]), ''))
lastval = tmp[K, 1:6]
lastday = tmp[K, 7:12]
ggp_data = data.frame(Day = lastday, val = lastval, cname = cname)
tmpdf = data.frame(tmp)
datelab = rev(rownames(tmpdf))[1]
fig2 <- ggplot() +
geom_line(data=tmpdf, aes(Italy_day, Italy), size=1, alpha=0.3, color='black') +
geom_line(data=tmpdf, aes(US_day, US), size=1, alpha=0.3, color='blue') +
geom_line(data=tmpdf, aes(Spain_day, Spain), size=1, alpha=0.3, color='red') +
geom_line(data=tmpdf, aes(France_day, France), size=1, alpha=0.3, color='cyan') +
geom_line(data=tmpdf, aes(Germany_day, Germany), size=1, alpha=0.3, color='magenta') +
geom_line(data=tmpdf, aes(UK_day, UK), size=1, alpha=0.3, color='orange') +
geom_point(data = ggp_data, aes(x=Day, y=val, color= cname),
size=3, alpha=0.8) +
#geom_label_repel(data = ggp_data, aes(x=Day, y=val, color= cname, label=cname),
#           nudge_x = 5, size = 3) +
scale_color_manual(values = c('cyan', 'magenta', 'black', 'red', 'orange', 'blue')) +
scale_y_continuous(breaks = c(log10(1), log10(5), log10(10), log10(seq(20,80,20))),
labels = c(1, 5, 10, seq(20,80,20))) +
theme_bw()
#annotation_logticks(scaled = FALSE, sides = 'l')
fig2out <- fig2 +
#coord_cartesian(ylim = c(0, 70), xlim = c(daystart, 0)) +
#coord_trans(y = 'log10') + #, ylim = c(0, 70), xlim = c(daystart, 0)) +
coord_cartesian(ylim = c(-0.3, 2), xlim = c(daystart, 0)) +
#coord_cartesian(ylim = c(0, 70)) +
labs(title = 'Daily Growth Rates of Total Confirmed Cases',
subtitle = datelab,
x= paste0('Days from today of Italy'),
y='Percentage') +
theme(plot.title = element_text(hjust = 0.5, size=rel(1)),
plot.subtitle = element_text(hjust = 0, size=rel(1)),
axis.text = element_text(size = rel(1) ),
axis.title = element_text(size=rel(1)),
legend.position = 'top', legend.title = element_blank(),
legend.text = element_text(size = rel(0.8)))
print(fig2out)
f2name = paste0(datelab, '_growthRate.png')
png(file.path(outPathGIF, f2name), width=6, height=4, units = "in", res=200)
Sys.sleep(2)
print(fig2out)
Sys.sleep(2)
dev.off()
Sys.sleep(2)
}
t2 = Sys.time(); t2-t1
###  gif, imageMagick installed, animation R pkcg installed
library(animation)
library(animation)
setwd('C:/forgithub/COVID19_LookAtUsTodaySeeYourselfTomorrow/gif_log_0419/')
pngfiles = list.files()
pngfiles
ani.options(interval = 0.25 )
t1=Sys.time()
im.convert(files = pngfiles, output = "gif_growthRates.gif")
t2 = Sys.time(); t2-t1
#curDate = Sys.Date(); print(curDate)
curDate = '2020-04-19'
setwd('C:/githubClone/COVID-19_LookAtUsToday_SeeYourselfTomorrow')
getwd()
## fetch TX county data from nytimes
url_nutimesCounty =
'https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv'
NYTcountyDat = read.csv(url_nutimesCounty, head=T)
# counties in Texas
ind = (NYTcountyDat$state == 'Texas')
TXcountyDat = NYTcountyDat[ind, ]
tail(TXcountyDat)
## COVID-19: Look at us today, see yourself tomorrow
## Look at us today, see yourself tomorrow - NY Governor Andrew Cuomo
## Jungsik Noh, UTSW, Dallas, TX
##
# Updates:
## source functions
t1 = Sys.time()
#curDate = Sys.Date(); print(curDate)
curDate = '2020-04-19'
#setwd('C:/githubClone/COVID-19_LookAtUsToday_SeeYourselfTomorrow')
getwd()
source(file.path(getwd(), 'cvd_state_matchedProjected.R'))
source(file.path(getwd(), 'cvd_country_matchedProjected.R'))
source(file.path(getwd(), 'cvd_county_matchedProjected.R'))
library(ggplot2)
library(data.table)
library(formattable)
library(ggpubr)
# fetch JHU
urlJhu = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'
jhudat = read.csv(urlJhu, head=T)
# china curation
idPrv = which(jhudat$Country.Region=='China')
chinaPrv = jhudat[idPrv, ]
chinaPrvTS = chinaPrv[, 5:ncol(jhudat)]
chinaTS = colSums(chinaPrvTS)
chinaHead = data.frame(Province.State='', 'Country.Region'='China', Lat=NA, Long=NA)
chinaDP = cbind(chinaHead, rbind(chinaTS))
jhudat = rbind(chinaDP, jhudat[-idPrv, ])
head(jhudat)
# canada curation
idPrv = which(jhudat$Country.Region=='Canada')
chinaPrv = jhudat[idPrv, ]
chinaPrvTS = chinaPrv[, 5:ncol(jhudat)]
chinaTS = colSums(chinaPrvTS)
chinaHead = data.frame(Province.State='', 'Country.Region'='Canada', Lat=NA, Long=NA)
chinaDP = cbind(chinaHead, rbind(chinaTS))
jhudat = rbind(chinaDP, jhudat[-idPrv, ])
head(jhudat)
write.csv(jhudat, file.path(getwd(), 'JHU_CSSE_covid19_confirmed_global.csv'))
### fetch states data from covidtracking.com
#url2 = 'https://covidtracking.com/api/v1/states/daily.csv'
#covidtrackingDat = read.csv(url2, head=T)
## daily input dataset
#write.csv(covidtrackingDat, file.path(getwd(), 'covidtracking_dot_com.csv'))
#head(covidtrackingDat[, 1:7])
# csv input files
basicDatasetsDir = file.path(getwd(), 'basicDatasets')
populationData = read.csv(file.path(basicDatasetsDir, 'usItalyKorea_Population2020UN.csv'))
stpopulationData =
read.csv(file.path(basicDatasetsDir, 'USstatesPopulation_USCensusBureau_simplified.csv'))
## Global parameters
#stname = 'TX'
#totalCases_threshold_toSetStart = 100
regionOfInt = c('Korea', 'Italy', 'X')
mvWin = 3
########################
##  TX counties
########################
totalCases_threshold_toSetStart = 50
totCases_thrshld_toSelectCnt = 200
## fetch TX county data from nytimes
url_nutimesCounty =
'https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv'
NYTcountyDat = read.csv(url_nutimesCounty, head=T)
# counties in Texas
ind = (NYTcountyDat$state == 'Texas')
TXcountyDat = NYTcountyDat[ind, ]
# daily input dataset
write.csv(TXcountyDat, file.path(getwd(), 'TXcounty_nytimes.csv'))
tail(TXcountyDat)
# read TX county population
#numCnt = 10
popTXcounty= read.csv(file.path(basicDatasetsDir, 'worldpopulationReviewdotcom_2020_TexasCounty.csv'))
# county sorting
ind = (TXcountyDat$date == curDate)
txcntToday = TXcountyDat[ind, ]
txcntToday_morethan200 = txcntToday[txcntToday$cases > totCases_thrshld_toSelectCnt, ]
curCases = txcntToday_morethan200$cases
scases = sort(curCases, index.return = T, decreasing = T)
txcntToday_sorted = txcntToday_morethan200[scases$ix, ]
numCnt = nrow(txcntToday_sorted)
print(paste0('number of Counties: ', numCnt))
print(txcntToday_sorted)
sortedCounties = as.character(txcntToday_sorted$county)
print(sortedCounties)
# run counties
myCaptnLst_county = list()
for (i in 1:numCnt){
tmp = cvd_county_matchedProjected(curDate, sortedCounties[i], jhudat, TXcountyDat,
populationData, popTXcounty)
myCaptnLst_county[[i]] = tmp
print(tmp)
}
t2=Sys.time(); t2 - t1
## EOF
# assume input datasets are already loaded to workspace
print(getwd())
print(curDate)
head(sortedCounties)
# manual curation
Ctname = sortedCounties
Ctname[which(Ctname == "Fort Bend")] <- 'Fort-Bend'
Ctname[which(Ctname == "El Paso")] <- 'El-Paso'
outPath4 = file.path(getwd(), 'output', 'TX_counties_uptodate')
if (file.exists(file.path(outPath4, 'Fort Bend_3plot_combined.png'))) {
file.copy(file.path(outPath4, 'Fort Bend_3plot_combined.png'),
file.path(outPath4, 'Fort-Bend_3plot_combined.png'), overwrite = T)
}
if (file.exists(file.path(outPath4, 'El Paso_3plot_combined.png'))) {
file.copy(file.path(outPath4, 'El Paso_3plot_combined.png'),
file.path(outPath4, 'El-Paso_3plot_combined.png'), overwrite = T)
}
repname3 = 'DAILY_REPORT_TX_COUNTY.md'
sink(file.path(getwd(), repname3))
cat('<img align="right"  height="100" src="/doc/utsw-master-logo-cmyk+BI.png">')
cat('\n\n', '<p>&nbsp;</p>', '\n\n', '<p>&nbsp;</p>', '\n\n')
cat(paste0('## ', curDate, ', COVID-19 Time Series', '\n'))
cat('# TX counties with cumulative confirmed cases > 200\n')
cat('\n\n', '<p>&nbsp;</p>', '\n\n')
for (i in 1:length(Ctname)){
getImg = paste0('>![img](/output/TX_counties_uptodate/',
Ctname[i], '_3plot_combined.png)')
cat(getImg)
cat('\n\n', '<p>&nbsp;</p>', '\n\n')
}
sink()
