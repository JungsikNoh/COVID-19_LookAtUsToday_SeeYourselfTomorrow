url_nutimesCounty =
'https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv'
NYTcountyDat = read.csv(url_nutimesCounty, head=T)
# counties in Texas
ind = (NYTcountyDat$state == 'Texas')
TXcountyDat = NYTcountyDat[ind, ]
tail(TXcountyDat)
View(TXcountyDat)
# county sorting
ind = (TXcountyDat$date == curDate)
txcntToday = TXcountyDat[ind, ]
View(txcntToday)
# assume input datasets are already loaded to workspace
print(getwd())
print(curDate)
##
##  country report
##
head(countryNamePop)
# curation
cname = countryNamePop$Region
# name curation for white spaces
whspInd = rep(0, nrow(countryNamePop))
cname2 = rep(NA, nrow(countryNamePop))
for (i in 1:(numCntr+1)){
x = cname[i]
y = chartr(' ', '\u00a0', x)
whspInd[i] = (x != y)
cname2[i] = y
}
#levels(cname)[levels(cname) == 'Korea, South'] <- 'Korea,-South'
#levels(cname)[levels(cname) == 'United Kingdom'] <- 'United-Kingdom'
#levels(cname)[levels(cname) == 'Saudi Arabia'] <- 'Saudi-Arabia'
#cnamePop = cbind(cname2, countryNamePop[,2:3])
outPath3 = file.path(getwd(), 'output', 'countries_uptodate')
for (i in which(whspInd==1)){
#print(i)
if (file.exists(file.path(outPath3, paste0(cname[i], '_3plot_combined.png')))) {
file.copy(file.path(outPath3, paste0(cname[i], '_3plot_combined.png')),
file.path(outPath3, paste0(cname2[i], '_3plot_combined.png')), overwrite = T)
}
}
#if (file.exists(file.path(outPath3, 'Korea, South_3plot_combined.png'))) {
#  file.copy(file.path(outPath3, 'Korea, South_3plot_combined.png'),
#            file.path(outPath3, 'Korea,-South_3plot_combined.png'), overwrite = T)
#}
repname1 = 'DAILY_REPORT_COUNTRY.md'
sink(file.path(getwd(), repname1))
cat('<img align="right"  height="100" src="/doc/utsw-master-logo-cmyk+BI.png">')
cat('\n\n', '<p>&nbsp;</p>', '\n\n', '<p>&nbsp;</p>', '\n\n')
cat(paste0('## ', curDate, ', COVID-19 Time Series', '\n'))
cat('# Countries (top 50)\n')
cat('\n\n', '<p>&nbsp;</p>', '\n\n')
for (i in 1:numCntr){
cat(paste0(i, '. ', cname2[i], ' <p>\n'))
getImg = paste0('>![img](/output/countries_uptodate/',
cname2[i], '_3plot_combined.png)')
cat(getImg)
cat('\n\n', '<p>&nbsp;</p>', '\n\n')
}
cat(paste0(cname2[51], ' <p>\n'))
getImg = paste0('>![img](/output/countries_uptodate/',
cname2[51], '_3plot_combined.png)')
cat(getImg)
cat('\n\n', '<p>&nbsp;</p>', '\n\n')
sink()
##
##  states report
##
head(sortedStates)
repname2 = 'DAILY_REPORT_STATE.md'
sink(file.path(getwd(), repname2))
cat('<img align="right"  height="100" src="/doc/utsw-master-logo-cmyk+BI.png">')
cat('\n\n', '<p>&nbsp;</p>', '\n\n', '<p>&nbsp;</p>', '\n\n')
cat(paste0('## ', curDate, ', COVID-19 Time Series', '\n'))
cat('# States in the U.S.\n')
cat('\n\n', '<p>&nbsp;</p>', '\n\n')
for (i in 1:length(sortedStates)){
fnametmp = paste0(sortedStates[i], '_3plot_combined.png')
if (file.exists(file.path(getwd(), 'output', 'states_uptodate', fnametmp))) {
getImg = paste0('>![img](/output/states_uptodate/', fnametmp, ')')
cat(getImg)
cat('\n\n', '<p>&nbsp;</p>', '\n\n')
}
}
sink()
##
numState = length(sortedStates)
StateAbb = sortedStates
myCaptnLst = list()
for (i in 1:22){ #numState){
tmp = cvd_state_matchedProjected(curDate, StateAbb[i], jhudat, covidtrackingDat,
populationData, stpopulationData)
myCaptnLst[[i]] = tmp
print(tmp)
}
##  states report
##
head(sortedStates)
repname2 = 'DAILY_REPORT_STATE.md'
sink(file.path(getwd(), repname2))
cat('<img align="right"  height="100" src="/doc/utsw-master-logo-cmyk+BI.png">')
cat('\n\n', '<p>&nbsp;</p>', '\n\n', '<p>&nbsp;</p>', '\n\n')
cat(paste0('## ', curDate, ', COVID-19 Time Series', '\n'))
cat('# States in the U.S.\n')
cat('\n\n', '<p>&nbsp;</p>', '\n\n')
for (i in 1:length(sortedStates)){
fnametmp = paste0(sortedStates[i], '_3plot_combined.png')
if (file.exists(file.path(getwd(), 'output', 'states_uptodate', fnametmp))) {
getImg = paste0('>![img](/output/states_uptodate/', fnametmp, ')')
cat(getImg)
cat('\n\n', '<p>&nbsp;</p>', '\n\n')
}
}
sink()
head(covidtrackingDat[, 1:7])
## COVID-19: Look at us today, see yourself tomorrow
## Look at us today, see yourself tomorrow - NY Governor Andrew Cuomo
## Jungsik Noh, UTSW, Dallas, TX
##
# Updates:
## source functions
t1 = Sys.time()
#curDate = Sys.Date(); print(curDate)
curDate = '2020-07-20'
#setwd('C:/githubClone/COVID-19_LookAtUsToday_SeeYourselfTomorrow')
getwd()
source(file.path(getwd(), 'cvd_state_matchedProjected.R'))
source(file.path(getwd(), 'cvd_country_matchedProjected.R'))
source(file.path(getwd(), 'cvd_county_matchedProjected.R'))
library(ggplot2)
library(data.table)
library(formattable)
library(ggpubr)
# fetch JHU
urlJhu = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'
jhudat = read.csv(urlJhu, head=T)
# china curation
idPrv = which(jhudat$Country.Region=='China')
chinaPrv = jhudat[idPrv, ]
chinaPrvTS = chinaPrv[, 5:ncol(jhudat)]
chinaTS = colSums(chinaPrvTS)
chinaHead = data.frame(Province.State='', 'Country.Region'='China', Lat=NA, Long=NA)
chinaDP = cbind(chinaHead, rbind(chinaTS))
jhudat = rbind(chinaDP, jhudat[-idPrv, ])
head(jhudat)
# canada curation
idPrv = which(jhudat$Country.Region=='Canada')
chinaPrv = jhudat[idPrv, ]
chinaPrvTS = chinaPrv[, 5:ncol(jhudat)]
chinaTS = colSums(chinaPrvTS)
chinaHead = data.frame(Province.State='', 'Country.Region'='Canada', Lat=NA, Long=NA)
chinaDP = cbind(chinaHead, rbind(chinaTS))
jhudat = rbind(chinaDP, jhudat[-idPrv, ])
head(jhudat)
write.csv(jhudat, file.path(getwd(), 'JHU_CSSE_covid19_confirmed_global.csv'))
### fetch states data from covidtracking.com
#url2 = 'https://covidtracking.com/api/v1/states/daily.csv'
#covidtrackingDat = read.csv(url2, head=T)
## daily input dataset
#write.csv(covidtrackingDat, file.path(getwd(), 'covidtracking_dot_com.csv'))
#head(covidtrackingDat[, 1:7])
# csv input files
basicDatasetsDir = file.path(getwd(), 'basicDatasets')
populationData = read.csv(file.path(basicDatasetsDir, 'usItalyKorea_Population2020UN.csv'))
stpopulationData =
read.csv(file.path(basicDatasetsDir, 'USstatesPopulation_USCensusBureau_simplified.csv'))
## Global parameters
#stname = 'TX'
#totalCases_threshold_toSetStart = 100
regionOfInt = c('Korea', 'Italy', 'X')
mvWin = 3
########################
##  TX counties
########################
totalCases_threshold_toSetStart = 50
totCases_thrshld_toSelectCnt = 600
## fetch TX county data from nytimes
url_nutimesCounty =
'https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv'
NYTcountyDat = read.csv(url_nutimesCounty, head=T)
# counties in Texas
ind = (NYTcountyDat$state == 'Texas')
TXcountyDat = NYTcountyDat[ind, ]
# daily input dataset
write.csv(TXcountyDat, file.path(getwd(), 'TXcounty_nytimes.csv'))
tail(TXcountyDat)
# read TX county population
#numCnt = 10
popTXcounty= read.csv(file.path(basicDatasetsDir, 'worldpopulationReviewdotcom_2020_TexasCounty.csv'))
# county sorting
ind = (TXcountyDat$date == curDate)
txcntToday = TXcountyDat[ind, ]
txcntToday_morethan200 = txcntToday[txcntToday$cases > totCases_thrshld_toSelectCnt, ]
curCases = txcntToday_morethan200$cases
scases = sort(curCases, index.return = T, decreasing = T)
txcntToday_sorted = txcntToday_morethan200[scases$ix, ]
numCnt = nrow(txcntToday_sorted)
print(paste0('number of Counties: ', numCnt))
print(txcntToday_sorted)
sortedCounties = as.character(txcntToday_sorted$county)
print(sortedCounties)
# run counties
myCaptnLst_county = list()
for (i in 1:numCnt){
tmp = cvd_county_matchedProjected(curDate, sortedCounties[i], jhudat, TXcountyDat,
populationData, popTXcounty)
myCaptnLst_county[[i]] = tmp
print(tmp)
}
t2=Sys.time(); t2 - t1
## EOF
##
head(sortedCounties)
# manual curation
Ctname = sortedCounties
Ctname[which(Ctname == "Fort Bend")] <- 'Fort-Bend'
Ctname[which(Ctname == "El Paso")] <- 'El-Paso'
outPath4 = file.path(getwd(), 'output', 'TX_counties_uptodate')
if (file.exists(file.path(outPath4, 'Fort Bend_3plot_combined.png'))) {
file.copy(file.path(outPath4, 'Fort Bend_3plot_combined.png'),
file.path(outPath4, 'Fort-Bend_3plot_combined.png'), overwrite = T)
}
if (file.exists(file.path(outPath4, 'El Paso_3plot_combined.png'))) {
file.copy(file.path(outPath4, 'El Paso_3plot_combined.png'),
file.path(outPath4, 'El-Paso_3plot_combined.png'), overwrite = T)
}
repname3 = 'DAILY_REPORT_TX_COUNTY.md'
sink(file.path(getwd(), repname3))
cat('<img align="right"  height="100" src="/doc/utsw-master-logo-cmyk+BI.png">')
cat('\n\n', '<p>&nbsp;</p>', '\n\n', '<p>&nbsp;</p>', '\n\n')
cat(paste0('## ', curDate, ', COVID-19 Time Series', '\n'))
cat('# TX counties with cumulative confirmed cases > 600\n')
cat('\n\n', '<p>&nbsp;</p>', '\n\n')
for (i in 1:length(Ctname)){
getImg = paste0('>![img](/output/TX_counties_uptodate/',
Ctname[i], '_3plot_combined.png)')
cat(getImg)
cat('\n\n', '<p>&nbsp;</p>', '\n\n')
}
sink()
cvd_county_matchedProjected
print(sortedCounties)
i
i=44
sortedCounties[i]
## fetch Italy, Korea and US data
outPath = file.path(getwd(), 'output', 'TX_counties', stname, curDate)
if (!dir.exists(outPath)) dir.create(outPath, recursive = T)
#
head(jhudat)
class(jhudat)
names(jhudat)
countryName = jhudat$Country.Region
head(countryName)
ind = which(countryName == 'Korea, South')
tmp = jhudat[ind,]
head(t(tmp))
tmp2 = t(tmp[5:length(tmp)])
#plot(tmp2)
#describe(jhudat)
KOts0 = tmp2
tmp = jhudat[which(countryName == 'Italy'),]
head(t(tmp))
tmp2 = t(tmp[5:length(tmp)])
#plot(tmp2)
ITts0 = tmp2
#
head(TXcountyDat)
class(TXcountyDat)
names(TXcountyDat)
head(TXcountyDat$date)
stdat1 = TXcountyDat[TXcountyDat$county == stname, ]
#stdat2 = stdat1[nrow(stdat1):1, ]
stdat3 = data.frame(date = stdat1$date, val = stdat1$cases)
colnames(stdat3) = c('date', stname)
# align jhu and covidtracking data
startDate0 = as.character(stdat3$date[1])
#st_y0 = startDate0 %% 10000
#st_mon0 = st_y0 %/% 100
#st_day0 = startDate0 %% 100
st_mon0 = month(startDate0)
st_day0 = mday(startDate0)
dateLab = paste0('X', st_mon0, '.',st_day0, '.', '20')
print(dateLab)
id1 = which(rownames(KOts0) == dateLab)
state_date = c(rep(NA, id1 - 1),  stdat3$date)
state_val = c(rep(NA, id1 - 1),  stdat3[, 2])
# check today date on two datasets
if (length(KOts0) != length(state_val)) stop('JHU date does not match to covidtracking.com data!')
# start with 'datf'
datf = cbind(KOts0, ITts0, state_val)
## manual curation, two zeros in Italy and Korea from Wikipedia
datfrow = rownames(datf)
id = which(datfrow == 'X3.12.20')     # Italy
datf[id, 2] = 15113
id = which(datfrow == 'X3.22.20')     # Korea
datf[id, 1] = 8897
## export corrected 3 countries data
datf = as.data.frame(datf)
colnames(datf) = c('Korea', 'Italy', 'X')
totalCases_3countries = datf
#write.csv(totalCases_3countries, 'totalCases_3countries.csv', row.names = T)
## population size adjustment
#populationData = read.csv('usItalyKorea_Population2020UN.csv')
KOpop = populationData$Population_2020_UN[(populationData$region == 'Korea')]
ITpop = populationData$Population_2020_UN[(populationData$region == 'Italy')]
## X population: popTXcounty
myStName = popTXcounty$CTYNAME
stInd = which(myStName == paste0(stname, ' County'))
if (length(stInd) == 0){ return() }
#stfullname = myStName[stInd]
#stfullname2 = paste0('.', stfullname)
#stpopulationData = read.csv('USstatesPopulation_USCensusBureau_simplified.csv')
#stInd2 = which(popTXcounty$CTYNAME == stfullname2)
Xpop = popTXcounty$Pop[stInd]
## pop adjustment: datf -> datf_adj
datf_adj = datf
datf_adj$Korea = round(datf$Korea * (Xpop/KOpop))
datf_adj$Italy = round(datf$Italy * (Xpop/ITpop))
# totalCases_threshold_toSetStart
d0 = apply(datf, 2, function(x) min(which(x > totalCases_threshold_toSetStart)))
d0
#
numTS = dim(datf_adj)[2]
lenTS = dim(datf_adj)[1]
TSthresholded = list()
datf2 = data.frame(Day = 1:lenTS - 1)
for (j in 1:numTS){
TSthresholded[[j]] = datf_adj[d0[j]:lenTS, j]
datf2 = add.col(datf2, TSthresholded[[j]])
}
longestLen = max(as.numeric(lapply(TSthresholded, length)))
datf2 = datf2[1:longestLen,]
tail(datf2)
tmpNames = cbind('Day', rbind(regionOfInt))
colnames(datf2) = tmpNames
## Daily new confirmed cases
A1 = datf2[,1+1:numTS]
A2 = rbind(rep(NA, numTS), A1[1:(longestLen-1),])
A3 = A1 - A2
# rarely it is negative. make it 0.
A3 = pmax(A3, 0)
A4 = (A3 / A2) * 100
## source functions
t1 = Sys.time()
#curDate = Sys.Date(); print(curDate)
curDate = '2020-07-20'
#setwd('C:/githubClone/COVID-19_LookAtUsToday_SeeYourselfTomorrow')
getwd()
source(file.path(getwd(), 'cvd_state_matchedProjected.R'))
source(file.path(getwd(), 'cvd_country_matchedProjected.R'))
source(file.path(getwd(), 'cvd_county_matchedProjected.R'))
library(ggplot2)
library(data.table)
library(formattable)
library(ggpubr)
# fetch JHU
urlJhu = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'
jhudat = read.csv(urlJhu, head=T)
# china curation
idPrv = which(jhudat$Country.Region=='China')
chinaPrv = jhudat[idPrv, ]
chinaPrvTS = chinaPrv[, 5:ncol(jhudat)]
chinaTS = colSums(chinaPrvTS)
chinaHead = data.frame(Province.State='', 'Country.Region'='China', Lat=NA, Long=NA)
chinaDP = cbind(chinaHead, rbind(chinaTS))
jhudat = rbind(chinaDP, jhudat[-idPrv, ])
head(jhudat)
# canada curation
idPrv = which(jhudat$Country.Region=='Canada')
chinaPrv = jhudat[idPrv, ]
chinaPrvTS = chinaPrv[, 5:ncol(jhudat)]
chinaTS = colSums(chinaPrvTS)
chinaHead = data.frame(Province.State='', 'Country.Region'='Canada', Lat=NA, Long=NA)
chinaDP = cbind(chinaHead, rbind(chinaTS))
jhudat = rbind(chinaDP, jhudat[-idPrv, ])
head(jhudat)
write.csv(jhudat, file.path(getwd(), 'JHU_CSSE_covid19_confirmed_global.csv'))
### fetch states data from covidtracking.com
#url2 = 'https://covidtracking.com/api/v1/states/daily.csv'
#covidtrackingDat = read.csv(url2, head=T)
## daily input dataset
#write.csv(covidtrackingDat, file.path(getwd(), 'covidtracking_dot_com.csv'))
#head(covidtrackingDat[, 1:7])
# csv input files
basicDatasetsDir = file.path(getwd(), 'basicDatasets')
populationData = read.csv(file.path(basicDatasetsDir, 'usItalyKorea_Population2020UN.csv'))
stpopulationData =
read.csv(file.path(basicDatasetsDir, 'USstatesPopulation_USCensusBureau_simplified.csv'))
## Global parameters
#stname = 'TX'
#totalCases_threshold_toSetStart = 100
regionOfInt = c('Korea', 'Italy', 'X')
mvWin = 3
########################
##  TX counties
########################
totalCases_threshold_toSetStart = 50
totCases_thrshld_toSelectCnt = 600
## fetch TX county data from nytimes
url_nutimesCounty =
'https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv'
NYTcountyDat = read.csv(url_nutimesCounty, head=T)
# counties in Texas
ind = (NYTcountyDat$state == 'Texas')
TXcountyDat = NYTcountyDat[ind, ]
# daily input dataset
write.csv(TXcountyDat, file.path(getwd(), 'TXcounty_nytimes.csv'))
tail(TXcountyDat)
# read TX county population
#numCnt = 10
popTXcounty= read.csv(file.path(basicDatasetsDir, 'worldpopulationReviewdotcom_2020_TexasCounty.csv'))
# county sorting
ind = (TXcountyDat$date == curDate)
txcntToday = TXcountyDat[ind, ]
txcntToday_morethan200 = txcntToday[txcntToday$cases > totCases_thrshld_toSelectCnt, ]
curCases = txcntToday_morethan200$cases
scases = sort(curCases, index.return = T, decreasing = T)
txcntToday_sorted = txcntToday_morethan200[scases$ix, ]
numCnt = nrow(txcntToday_sorted)
print(paste0('number of Counties: ', numCnt))
print(txcntToday_sorted)
sortedCounties = as.character(txcntToday_sorted$county)
print(sortedCounties)
i
add.col <- function(df, new.col) {
df = cbind(df)
n.row<-dim(df)[1]
length(new.col)<-n.row
#tmp <- cbind(rep(NA, n.row))
#tmp[(n.row - length(new.col) + 1):n.row] <- new.col
cbind(df, new.col)
}
myFilter <- function(x, mwSize, lastDay){
y = x
halfSize = (mwSize - 1) / 2
for (i in 2:lastDay){
sti = max(2, i - halfSize)
endi = min(lastDay, i + halfSize)
slc = x[sti:endi]
y[i] = mean(slc, na.rm = T)
}
return(y)
}
## fetch Italy, Korea and US data
outPath = file.path(getwd(), 'output', 'TX_counties', stname, curDate)
if (!dir.exists(outPath)) dir.create(outPath, recursive = T)
#
head(jhudat)
class(jhudat)
names(jhudat)
countryName = jhudat$Country.Region
head(countryName)
ind = which(countryName == 'Korea, South')
tmp = jhudat[ind,]
head(t(tmp))
tmp2 = t(tmp[5:length(tmp)])
#plot(tmp2)
#describe(jhudat)
KOts0 = tmp2
tmp = jhudat[which(countryName == 'Italy'),]
head(t(tmp))
tmp2 = t(tmp[5:length(tmp)])
#plot(tmp2)
ITts0 = tmp2
#
head(TXcountyDat)
class(TXcountyDat)
names(TXcountyDat)
head(TXcountyDat$date)
stdat1 = TXcountyDat[TXcountyDat$county == stname, ]
#stdat2 = stdat1[nrow(stdat1):1, ]
stdat3 = data.frame(date = stdat1$date, val = stdat1$cases)
colnames(stdat3) = c('date', stname)
# align jhu and covidtracking data
startDate0 = as.character(stdat3$date[1])
#st_mon0 = st_y0 %/% 100
#st_day0 = startDate0 %% 100
st_mon0 = month(startDate0)
st_day0 = mday(startDate0)
dateLab = paste0('X', st_mon0, '.',st_day0, '.', '20')
print(dateLab)
id1 = which(rownames(KOts0) == dateLab)
state_date = c(rep(NA, id1 - 1),  stdat3$date)
state_val = c(rep(NA, id1 - 1),  stdat3[, 2])
# check today date on two datasets
if (length(KOts0) != length(state_val)) stop('JHU date does not match to covidtracking.com data!')
# start with 'datf'
datf = cbind(KOts0, ITts0, state_val)
## manual curation, two zeros in Italy and Korea from Wikipedia
datfrow = rownames(datf)
id = which(datfrow == 'X3.12.20')     # Italy
datf[id, 2] = 15113
id = which(datfrow == 'X3.22.20')     # Korea
datf[id, 1] = 8897
## export corrected 3 countries data
datf = as.data.frame(datf)
colnames(datf) = c('Korea', 'Italy', 'X')
totalCases_3countries = datf
#write.csv(totalCases_3countries, 'totalCases_3countries.csv', row.names = T)
## population size adjustment
#populationData = read.csv('usItalyKorea_Population2020UN.csv')
KOpop = populationData$Population_2020_UN[(populationData$region == 'Korea')]
ITpop = populationData$Population_2020_UN[(populationData$region == 'Italy')]
## X population: popTXcounty
myStName = popTXcounty$CTYNAME
stInd = which(myStName == paste0(stname, ' County'))
if (length(stInd) == 0){ return() }
#stfullname = myStName[stInd]
#stfullname2 = paste0('.', stfullname)
state_date
